services:
  # train:
  #   container_name: train
  #   build: 
  #     context: services/train
  #   volumes:
  #     - ./data/input/:/input
  #     - ./data/output/model/raw:/model
  #     - ./data/output/tokenizer/:/tokenizer
  #     - ./services/train/src:/app
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   shm_size: '2gb'
  #   command: python /app/main.py
  # optimization:
  #   build:
  #     context: services/optimization
  #   volumes:
  #     - ./data/output/model/raw:/model/raw
  #     - ./data/output/model/onnx:/model/onnx
  #   depends_on:
  #     train:
  #       condition: service_completed_successfully
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]
  #   shm_size: '2gb'
  #   command: optimum-cli export onnx --model=/model/raw/ --task sequence-classification --optimize O1 --sequence_length 300  /model/onnx/
  inference:
    image: nvcr.io/nvidia/tritonserver:23.03-py3
    volumes:
      - ./data/output/model/onnx/:/models/readability/1/
      - ./services/inference/model/config.pbtxt:/models/readability/config.pbtxt
    # depends_on:
    #   optimization:
    #     condition: service_completed_successfully
    command: tritonserver --model-repository=/models
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/v2/health/ready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
  api:
    build:
      context: services/api
    ports:
      - 5000:5000
    volumes:
      - ./data/output/tokenizer/:/tokenizer
      - ./services/api/src:/app
    depends_on:
      inference:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/alive"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    command: python /app/main.py
  # load_testing:
  #   build:
  #     context: services/load_testing
  #   volumes:
  #     - ./services/load_testing/src:/app
  #     - ./data/input/:/input
  #   depends_on:
  #     api:
  #       condition: service_healthy
  #   command: -f /app/main.py  --headless -u 200 -r 10 --run-time 120